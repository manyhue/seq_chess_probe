{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "## allow interaction with the plots\n",
    "%matplotlib widget\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# add the main directory reference and import 'imports.py'\n",
    "import sys\n",
    "import os\n",
    "\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.insert(0, \"..\")\n",
    "from imports import *\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(level=logging.WARN)\n",
    "\n",
    "__builtins__.verbosity = 4\n",
    "# Set the HF_HOME environment variable\n",
    "os.environ[\"HF_HOME\"] = \"/run/media/HUNK/DATASETS/HF\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a few global data/train params\n",
    "from lib.optim import WarmupCosineLR\n",
    "from typing import override\n",
    "from lib.train import *\n",
    "\n",
    "\n",
    "class params:\n",
    "    num_workers = 24\n",
    "    batch_size = 2048\n",
    "    seq_len = 182\n",
    "    files_per_epoch = 1000\n",
    "\n",
    "    max_epochs = 100\n",
    "    lr = 0.005\n",
    "\n",
    "    flush_epoch_units = False\n",
    "    loss_every = 1000\n",
    "\n",
    "\n",
    "# customize trainer\n",
    "class SeqTrainer(Trainer):\n",
    "    @override\n",
    "    def prepare_batch(self, batch):\n",
    "        if self.gpus:\n",
    "            # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)\n",
    "            batch = batch[0].pin_memory().to(self.device, non_blocking=True)\n",
    "        else:\n",
    "            batch = batch[0].to(self.device)\n",
    "        return batch[:, :-1], batch[:, 1:]\n",
    "\n",
    "    # from nanogpt\n",
    "    @override\n",
    "    def prepare_optimizer(self, weight_decay, learning_rate, betas, device_type):\n",
    "        # start with all of the candidate parameters\n",
    "        param_dict = {pn: p for pn, p in self.model.named_parameters()}\n",
    "        # filter out those that do not require grad\n",
    "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
    "        # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
    "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
    "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
    "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
    "        optim_groups = [\n",
    "            {\"params\": decay_params, \"weight_decay\": weight_decay},\n",
    "            {\"params\": nodecay_params, \"weight_decay\": 0.0},\n",
    "        ]\n",
    "        num_decay_params = sum(p.numel() for p in decay_params)\n",
    "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
    "        print(\n",
    "            f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\"\n",
    "        )\n",
    "        print(\n",
    "            f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\"\n",
    "        )\n",
    "        # Create AdamW optimizer and use the fused version if it is available\n",
    "        fused_available = \"fused\" in inspect.signature(torch.optim.AdamW).parameters\n",
    "        use_fused = fused_available and device_type == \"cuda\"\n",
    "        extra_args = dict(fused=True) if use_fused else dict()\n",
    "        self.optim = torch.optim.AdamW(\n",
    "            optim_groups, lr=learning_rate, betas=betas, **extra_args\n",
    "        )\n",
    "\n",
    "        self.sched = WarmupCosineLR(\n",
    "            self.optim,\n",
    "            warmup_iters=200,\n",
    "            min_lr=6e-6,\n",
    "            lr_decay_iters=10000,\n",
    "            lr=params.lr,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loader 0 (IterableDataset) Preview:\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ARCHIVE/Personal/2186474940/.pixi/envs/dev/lib/python3.12/multiprocessing/popen_fork.py:66: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
      "In addition, using fork() with Python in general is a recipe for mysterious\n",
      "deadlocks and crashes.\n",
      "\n",
      "The most likely reason you are seeing this error is because you are using the\n",
      "multiprocessing module on Linux, which uses fork() by default. This will be\n",
      "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
      "\n",
      "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
      "\n",
      "If you really know what your doing, you can silence this warning with the warning module\n",
      "or by setting POLARS_ALLOW_FORKING_THREAD=1.\n",
      "\n",
      "  self.pid = os.fork()\n",
      "illegal san: 'Ke4' in 8/4R3/1p6/4p2k/1r4p1/4K1P1/5P2/8 w - - 2 45 while parsing <Game at 0x7aa938be3d10 ('Jumabayev Rinat (KAZ)' vs. 'Caruana Fabiano (USA)', '2021.07.18' at 'Sochi')>\n",
      "illegal san: 'Kd5' in 8/P4R2/3k1pp1/4p2p/2K5/3P3P/5PP1/r7 b - - 5 48 while parsing <Game at 0x7aa92bac61b0 ('Harikrishna Pentala (IND)' vs. 'Lupulescu Constantin (ROU)', '2021.07.18' at 'Sochi')>\n",
      "illegal san: 'Ke4' in 8/8/8/4k1p1/2r5/R4K1P/5P2/8 w - - 10 48 while parsing <Game at 0x7aa938a95b50 ('Sevian Samuel (USA)' vs. 'Duda Jan-Krzysztof (POL)', '2021.07.18' at 'Sochi')>\n",
      "illegal san: 'Kd4' in 8/8/4n1P1/4p3/8/1pk1K3/p6P/5R2 w - - 1 65 while parsing <Game at 0x7aa938adff20 ('Gareyev Timur (USA)' vs. 'Fedoseev Vladimir (RUS)', '2021.07.18' at 'Sochi')>\n",
      "illegal san: 'Ke5' in 8/8/7p/R7/4k3/5rRK/1r6/8 b - - 6 51 while parsing <Game at 0x7aa938af3560 ('Shankland Sam (USA)' vs. 'Areshchenko Alexander (UKR)', '2021.07.18' at 'Sochi')>\n",
      "/ARCHIVE/Personal/2186474940/.pixi/envs/dev/lib/python3.12/multiprocessing/popen_fork.py:66: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
      "In addition, using fork() with Python in general is a recipe for mysterious\n",
      "deadlocks and crashes.\n",
      "\n",
      "The most likely reason you are seeing this error is because you are using the\n",
      "multiprocessing module on Linux, which uses fork() by default. This will be\n",
      "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
      "\n",
      "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
      "\n",
      "If you really know what your doing, you can silence this warning with the warning module\n",
      "or by setting POLARS_ALLOW_FORKING_THREAD=1.\n",
      "\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constituent shapes:\n",
      "batch[0]: torch.Size([32, 129]), torch.int64\n",
      "\n",
      "First 5 samples:\n",
      "\n",
      "Sample 0: \n",
      "\n",
      "tensor([1435, 5189, 1441, 5135, 1404, 5329, 1256, 4943, 1373, 5024, 1010, 4097,\n",
      "         128, 5422, 1443, 5299, 1410, 4365, 1495, 4985, 1469, 5078,  302, 7789,\n",
      "        1528, 4333, 1532, 4390, 2091, 6156, 1060, 5948, 2168, 4727, 1533, 5442,\n",
      "        1341, 5968, 1032, 5235,  366, 5231, 3012, 5043,  775, 5888,  450, 4937,\n",
      "        3795, 7009,  835, 5540, 3821, 5266, 1378, 5230, 1321, 7449, 1345, 5895,\n",
      "        3343, 5843, 1120, 5807, 3377, 7684, 1472, 5417, 3488, 7233, 3545, 4783,\n",
      "        1085, 5042, 1351, 4723, 3712, 7784, 3736, 5140, 1120, 7117, 1087, 5326,\n",
      "        3629, 5188,  385, 4663,  466, 7092, 3654, 5093,  338, 7314, 3592, 7301,\n",
      "        3153, 7331,  896, 7444,  844, 7554, 1348, 4723, 3482, 4657, 3378, 7530,\n",
      "        3600, 7751, 3637, 7731,  780, 7402,  732, 7511, 3523, 4599, 1465, 7528,\n",
      "        3310, 4546, 3861, 7568, 3523, 4599, 3306, 7528, 3419])\n",
      "\n",
      "Sample 1: \n",
      "\n",
      "tensor([1435, 5189, 1441, 5135, 1404, 5329, 1256, 5326, 1216, 5422, 1373, 5024,\n",
      "         128, 4333, 1010, 4728, 2086, 5235,  365, 5231, 1760, 5391, 1181, 7563,\n",
      "        3012, 5360, 1064, 6165, 1605, 7457,  777, 5229, 1341, 4943,  292, 4981,\n",
      "         218, 7444, 3567, 4393, 3455, 4923,  301, 4842, 1528, 7548,  211, 4329,\n",
      "         141, 7330, 1410, 3987, 1169, 5355, 1380, 4985, 1216, 5386, 1060, 7342,\n",
      "        3345, 4936, 3472, 4248, 3510, 4308, 1031, 7006, 3404, 3902, 1091, 4832,\n",
      "        1028, 4223, 3448, 4773, 3665, 4833, 3554, 4097, 3467, 4087, 1496, 4777,\n",
      "         991, 4364, 1070, 4173, 1137, 4773, 3250, 3998, 3360, 7121,  891, 7457,\n",
      "        1465, 4237, 1173, 3927, 3415, 3980,   60, 5267, 1208, 4164, 3387, 3996,\n",
      "        3405, 7441, 1114, 3913, 1469, 5443, 1320, 3965,  313, 4044,  219, 4256,\n",
      "          93, 4324,  896, 4832,  156, 4130,  847, 4256,  221])\n",
      "\n",
      "Sample 2: \n",
      "\n",
      "tensor([1404, 5189, 1373, 5297, 1410, 5266, 1378, 5236, 1350, 5360, 1010, 5355,\n",
      "        1062, 4942, 1256, 4093, 1132, 6167, 1496, 4332,  367, 6489,  777, 5329,\n",
      "         524, 4728, 1220, 5325, 1303, 4248, 1319, 7562, 3010, 5291, 2088, 4900,\n",
      "         128, 4973, 3124, 5927, 1229, 4917, 3340, 5422, 3566, 7345, 1341, 7453,\n",
      "        1464, 6144, 1438, 4311, 3344, 5287, 1922, 5323, 3124, 7007,  452, 7233,\n",
      "        3382, 5350,  524, 4007,  450, 7449,  385, 7233, 3345, 5443,  470, 4975,\n",
      "         539, 5392, 3400, 3938, 1953, 6338, 2130, 6511, 3160, 7447,  891, 4842,\n",
      "         896, 4837, 1528, 4871, 3153, 7010,  849, 7559, 3480, 7003,  901, 4867,\n",
      "        1500, 6963,  956, 7009, 1434, 7447, 1438, 7003,  904, 6961, 1322, 6982,\n",
      "         852,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0])\n",
      "\n",
      "Sample 3: \n",
      "\n",
      "tensor([1404, 5189, 1373, 5297, 1410, 5266, 1378, 5236, 1350, 5360, 1010, 5355,\n",
      "        1062, 4942, 1256, 5135, 2092, 4901, 2196, 4991, 1434, 4332,  363, 4092,\n",
      "        2380, 3936, 2185, 5328, 1969, 6164, 1820, 4723, 1216, 4657, 1341, 5291,\n",
      "         126, 4244,  772, 5391, 1181, 5083,  714, 4977, 3790, 5287, 1321, 6999,\n",
      "        3339, 7785, 3014, 4604,  660, 3985,   64, 5421, 1527, 5443, 3566, 5415,\n",
      "        1215, 5413, 1498, 4661, 1152, 7235, 1465, 5068, 1112, 4155, 1438, 5323,\n",
      "        1468, 7679, 3345, 4068, 3408, 7607,  598, 7579,    1, 4244,  566, 7593,\n",
      "         598, 7579,  566, 7593,  598, 7579,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0])\n",
      "\n",
      "Sample 4: \n",
      "\n",
      "tensor([1404, 5189, 1373, 5360, 1256, 5297, 1410, 5266, 1414, 5389, 1378, 5236,\n",
      "        1434, 4332, 1320, 4728, 1341, 5135, 3004, 5023,  365, 5328,  126, 4248,\n",
      "        2089, 4309, 2106, 4093,  777, 4944, 1350, 4007, 3031, 6165,  288, 7004,\n",
      "        1751, 6337, 1011, 6501, 1215, 6527, 1438, 6979, 1466, 6677, 1153, 7560,\n",
      "        3013, 4922, 3453, 4951, 1496, 6492, 1440, 5355, 3566, 6157, 3349, 4920,\n",
      "        3236, 4883, 1103, 5043, 1009, 5970,  989, 5939,  891, 7120, 3341, 5444,\n",
      "        2312, 5137, 1030, 5072, 2470, 5733, 1325, 7196, 1058, 7088,  995, 7337,\n",
      "        1078, 4922, 1145, 5420,  901, 7072, 1214, 7049, 3229, 7156, 1119, 7226,\n",
      "        3454, 7144,  957, 4840,  912, 5441, 3344, 7181, 3386, 5322,  860, 5439,\n",
      "        1500, 5387, 1502, 6958, 3380, 5319, 3818, 6928, 3369, 5437,  799, 7699,\n",
      "        3261, 5435, 3304, 4777, 3318, 4769, 3303,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "from data.chessPgn import *\n",
    "\n",
    "\n",
    "dt = PGNData(PGNDataConfig.create(params))\n",
    "\n",
    "dt.preview()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 90.94M\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs progress:   0%|          | 0/100 [00:00<?, ?Epoch/s]illegal san: 'Ke4' in 8/4R3/1p6/4p2k/1r4p1/4K1P1/5P2/8 w - - 2 45 while parsing <Game at 0x7aa92bcb64e0 ('Jumabayev Rinat (KAZ)' vs. 'Caruana Fabiano (USA)', '2021.07.18' at 'Sochi')>\n",
      "illegal san: 'Kd5' in 8/P4R2/3k1pp1/4p2p/2K5/3P3P/5PP1/r7 b - - 5 48 while parsing <Game at 0x7aab6948c470 ('Harikrishna Pentala (IND)' vs. 'Lupulescu Constantin (ROU)', '2021.07.18' at 'Sochi')>\n",
      "illegal san: 'Ke4' in 8/8/8/4k1p1/2r5/R4K1P/5P2/8 w - - 10 48 while parsing <Game at 0x7aab6945b1d0 ('Sevian Samuel (USA)' vs. 'Duda Jan-Krzysztof (POL)', '2021.07.18' at 'Sochi')>\n",
      "illegal san: 'Kd4' in 8/8/4n1P1/4p3/8/1pk1K3/p6P/5R2 w - - 1 65 while parsing <Game at 0x7aab4ebe15b0 ('Gareyev Timur (USA)' vs. 'Fedoseev Vladimir (RUS)', '2021.07.18' at 'Sochi')>\n",
      "illegal san: 'Ke5' in 8/8/7p/R7/4k3/5rRK/1r6/8 b - - 6 51 while parsing <Game at 0x7aab693af380 ('Shankland Sam (USA)' vs. 'Areshchenko Alexander (UKR)', '2021.07.18' at 'Sochi')>\n",
      "Epochs progress:   0%|          | 0/100 [00:02<?, ?Epoch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 30\u001b[0m\n\u001b[1;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m GPT(GPTConfig(vocab_size\u001b[38;5;241m=\u001b[39mdt\u001b[38;5;241m.\u001b[39mclasses, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, seq_len\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mseq_len))\n\u001b[1;32m     19\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SeqTrainer(\n\u001b[1;32m     20\u001b[0m     TrainerConfig\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     21\u001b[0m         params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     )\n\u001b[1;32m     27\u001b[0m )\n\u001b[0;32m---> 30\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ARCHIVE/Personal/2186474940/lib/train.py:296\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, loaders)\u001b[0m\n\u001b[1;32m    293\u001b[0m _save_model_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;129;01min\u001b[39;00m epoch_bar:\n\u001b[0;32m--> 296\u001b[0m     epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m     epoch_bar\u001b[38;5;241m.\u001b[39mset_description(\n\u001b[1;32m    298\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs progress [Loss: \u001b[39m\u001b[38;5;132;01m{:.3e}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch_loss)\n\u001b[1;32m    299\u001b[0m     )\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_end_callback:\n",
      "File \u001b[0;32m/ARCHIVE/Personal/2186474940/lib/train.py:330\u001b[0m, in \u001b[0;36mTrainer._fit_epoch\u001b[0;34m(self, train_loader, val_loader, y_len)\u001b[0m\n\u001b[1;32m    328\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 330\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_grad_enabled\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/ARCHIVE/Personal/2186474940/.pixi/envs/dev/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m/ARCHIVE/Personal/2186474940/.pixi/envs/dev/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1448\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1448\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1451\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/ARCHIVE/Personal/2186474940/.pixi/envs/dev/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1412\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1409\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1411\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1412\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1413\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1414\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/ARCHIVE/Personal/2186474940/.pixi/envs/dev/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1243\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1231\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1243\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1244\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1245\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1246\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/ARCHIVE/Personal/2186474940/.pixi/envs/dev/lib/python3.12/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/ARCHIVE/Personal/2186474940/.pixi/envs/dev/lib/python3.12/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ARCHIVE/Personal/2186474940/.pixi/envs/dev/lib/python3.12/multiprocessing/connection.py:440\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 440\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/ARCHIVE/Personal/2186474940/.pixi/envs/dev/lib/python3.12/multiprocessing/connection.py:1136\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1136\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/ARCHIVE/Personal/2186474940/.pixi/envs/dev/lib/python3.12/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = GPT(GPTConfig(vocab_size=dt.classes, bias=True, seq_len=params.seq_len))\n",
    "\n",
    "trainer = SeqTrainer(\n",
    "    TrainerConfig.create(\n",
    "        params,\n",
    "        epoch_end_callback=dt.shuffle_files,\n",
    "        save_model_every=5,\n",
    "        load_previous=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "trainer.fit(model, dt.loaders())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 91.04M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ARCHIVE/Personal/2186474940/nb/../lib/modules.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(pth_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1256]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Ng1f3', 'pc7c5', 'Pc4d5', 'pe7e6', 'Nb1d2', 'ng8f6'], dtype='<U7')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from eval.play import ChessGame\n",
    "from lib.chess import chess_move_labels as le\n",
    "from models.nanoGPT import *\n",
    "\n",
    "\n",
    "model = GPT(\n",
    "    GPTConfig(vocab_size=len(le.classes_), bias=True, seq_len=1024)\n",
    ")\n",
    "\n",
    "model.load_from_pth(\n",
    "    \"../out/GPT__seq_len=1024__vocab_size=7797__n_layer=12__n_head=12__n_embd=768__dropout=0.0__bias=True__lr=0.005__weight_decay=0.01__epoch=0-28.pth\"\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "idx = torch.tensor(le.transform([\"Ng1f3\"])).view(1, -1).to(device)\n",
    "print(idx)\n",
    "result = model.generate(idx, 5).cpu()\n",
    "le.inverse_transform(result.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = ChessGame(model)\n",
    "game.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
