{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "## allow interaction with the plots\n",
    "%matplotlib widget\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# add the main directory reference and import 'imports.py'\n",
    "import sys\n",
    "import os\n",
    "from tnibs.user import *\n",
    "\n",
    "__builtins__.verbosity = 4\n",
    "\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.insert(0, \"..\")\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(level=logging.WARN)\n",
    "\n",
    "# Set the HF_HOME environment variable\n",
    "os.environ[\"HF_HOME\"] = \"/run/media/HUNK/DATASETS/HF\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class params:\n",
    "    num_workers = 24\n",
    "    # batch_size = 160\n",
    "    batch_size = 64\n",
    "    seq_len = 140\n",
    "    files_per_epoch = 800\n",
    "\n",
    "    max_epochs = 5\n",
    "    # lr = 0.005\n",
    "    lr = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnanoRWKV\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnanoGPT\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 7\u001b[0m rwkv_model \u001b[38;5;241m=\u001b[39m \u001b[43mRWKV\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGPTConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m140\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m rwkv_model\u001b[38;5;241m.\u001b[39mload_from_pth(\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout/RWKV__seq_len=140__vocab_size=7797__n_layer=12__n_head=12__n_embd=768__dropout=0.0__bias=True__ignore_index=0__lr=0.005__weight_decay=0.01__epoch=164-239.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m rwkv_model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/ARCHIVE/Personal/2186474940/models/nanoRWKV.py:218\u001b[0m, in \u001b[0;36mRWKV.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m config\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m config\u001b[38;5;241m.\u001b[39mseq_len \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleDict(\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    215\u001b[0m         wte\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mEmbedding(config\u001b[38;5;241m.\u001b[39mvocab_size, config\u001b[38;5;241m.\u001b[39mn_embd),\n\u001b[1;32m    216\u001b[0m         wpe\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mEmbedding(config\u001b[38;5;241m.\u001b[39mseq_len, config\u001b[38;5;241m.\u001b[39mn_embd),\n\u001b[1;32m    217\u001b[0m         drop\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mDropout(config\u001b[38;5;241m.\u001b[39mdropout),\n\u001b[0;32m--> 218\u001b[0m         h\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mModuleList([\u001b[43mBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mn_layer)]),\n\u001b[1;32m    219\u001b[0m         ln_f\u001b[38;5;241m=\u001b[39mLayerNorm(config\u001b[38;5;241m.\u001b[39mn_embd, bias\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mbias),\n\u001b[1;32m    220\u001b[0m     )\n\u001b[1;32m    221\u001b[0m )\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(config\u001b[38;5;241m.\u001b[39mn_embd, config\u001b[38;5;241m.\u001b[39mvocab_size, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66;03m# with weight tying when using torch.compile() some warnings get generated:\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;66;03m# \"UserWarning: functional_call was passed multiple values for tied weights.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# This behavior is deprecated and will be an error in future versions\"\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# not 100% sure what this is, so far seems to be harmless. TODO investigate\u001b[39;00m\n",
      "File \u001b[0;32m/ARCHIVE/Personal/2186474940/models/nanoRWKV.py:196\u001b[0m, in \u001b[0;36mBlock.__init__\u001b[0;34m(self, config, layer_id)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1 \u001b[38;5;241m=\u001b[39m LayerNorm(config\u001b[38;5;241m.\u001b[39mn_embd, bias\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mbias)\n\u001b[0;32m--> 196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtmix \u001b[38;5;241m=\u001b[39m \u001b[43mRWKV_TimeMix_x051a\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_2 \u001b[38;5;241m=\u001b[39m LayerNorm(config\u001b[38;5;241m.\u001b[39mn_embd, bias\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mbias)\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcmix \u001b[38;5;241m=\u001b[39m RWKV_ChannelMix_x051a(config, layer_id)\n",
      "File \u001b[0;32m/ARCHIVE/Personal/2186474940/models/nanoRWKV.py:43\u001b[0m, in \u001b[0;36mRWKV_TimeMix_x051a.__init__\u001b[0;34m(self, config, layer_id)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config, layer_id):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m config\u001b[38;5;241m.\u001b[39mn_embd \u001b[38;5;241m%\u001b[39m config\u001b[38;5;241m.\u001b[39mn_head \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mn_embd \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m config\u001b[38;5;241m.\u001b[39mn_head\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_head \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mn_head\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load models\n",
    "\n",
    "from lib.chess import chess_move_labels as le\n",
    "from models.nanoRWKV import *\n",
    "from models.nanoGPT import *\n",
    "\n",
    "config = GPTConfig(vocab_size=len(le.classes_), bias=True, seq_len=140)\n",
    "GPTConfig(vocab_size=len(le.classes_), bias=True, seq_len=140)\n",
    "\n",
    "rwkv_model = RWKV(GPTConfig(vocab_size=len(le.classes_), bias=True, seq_len=140))\n",
    "\n",
    "rwkv_model.load_from_pth(\n",
    "    \"out/RWKV__seq_len=140__vocab_size=7797__n_layer=12__n_head=12__n_embd=768__dropout=0.0__bias=True__ignore_index=0__lr=0.005__weight_decay=0.01__epoch=164-239.pth\"\n",
    ")\n",
    "\n",
    "rwkv_model.to(device)\n",
    "\n",
    "gpt_model = GPT(GPTConfig(vocab_size=len(le.classes_), bias=True, seq_len=140))\n",
    "\n",
    "gpt_model.load_from_pth(\n",
    "    \"out/GPT__seq_len=140__vocab_size=7797__n_layer=12__n_head=12__n_embd=768__dropout=0.0__bias=True__lr=0.01__weight_decay=0.01__epoch=133-226.pth\"\n",
    ")\n",
    "gpt_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 100 games to games_1.pgn\n",
      "Saved 100 games to games_2.pgn\n",
      "Saved 100 games to games_3.pgn\n",
      "Saved 100 games to games_4.pgn\n",
      "Saved 100 games to games_5.pgn\n",
      "Saved 100 games to games_6.pgn\n",
      "Saved 100 games to games_7.pgn\n",
      "Saved 100 games to games_8.pgn\n",
      "Saved 100 games to games_9.pgn\n",
      "Saved 100 games to games_10.pgn\n",
      "Saved 100 games to games_11.pgn\n",
      "Saved 100 games to games_12.pgn\n",
      "Saved 100 games to games_13.pgn\n",
      "Saved 100 games to games_14.pgn\n",
      "Saved 100 games to games_15.pgn\n",
      "Saved 100 games to games_16.pgn\n",
      "Saved 100 games to games_17.pgn\n",
      "Saved 100 games to games_18.pgn\n",
      "Saved 100 games to games_19.pgn\n",
      "Saved 100 games to games_20.pgn\n",
      "Saved 100 games to games_21.pgn\n",
      "Saved 100 games to games_22.pgn\n",
      "Saved 100 games to games_23.pgn\n",
      "Saved 100 games to games_24.pgn\n",
      "Saved 100 games to games_25.pgn\n",
      "Saved 100 games to games_26.pgn\n",
      "Saved 100 games to games_27.pgn\n",
      "Saved 100 games to games_28.pgn\n",
      "Saved 100 games to games_29.pgn\n",
      "Saved 100 games to games_30.pgn\n",
      "Saved 100 games to games_31.pgn\n",
      "Saved 100 games to games_32.pgn\n",
      "Saved 100 games to games_33.pgn\n",
      "Saved 100 games to games_34.pgn\n",
      "Saved 100 games to games_35.pgn\n",
      "Saved 100 games to games_36.pgn\n",
      "Saved 100 games to games_37.pgn\n",
      "Saved 100 games to games_38.pgn\n",
      "Saved 100 games to games_39.pgn\n",
      "Saved 100 games to games_40.pgn\n",
      "Saved 100 games to games_41.pgn\n",
      "Saved 100 games to games_42.pgn\n",
      "Saved 100 games to games_43.pgn\n",
      "Saved 100 games to games_44.pgn\n",
      "Saved 100 games to games_45.pgn\n",
      "Saved 100 games to games_46.pgn\n",
      "Saved 100 games to games_47.pgn\n",
      "Saved 100 games to games_48.pgn\n",
      "Saved 100 games to games_49.pgn\n",
      "Saved 100 games to games_50.pgn\n"
     ]
    }
   ],
   "source": [
    "# synthetic data\n",
    "\n",
    "from lib.chess import generate_random_games_to_pgn\n",
    "\n",
    "# with change_dir(\"resources/synthetic\"):\n",
    "#     generate_random_games_to_pgn(500, game_length=params.seq_len + 1)\n",
    "\n",
    "\n",
    "# with change_dir(\"resources/synthetic_val\"):\n",
    "#     generate_random_games_to_pgn(50, game_length=params.seq_len + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.pgnSeq import *\n",
    "\n",
    "synth_dt = PGNData(\n",
    "    PGNDataConfig.create(\n",
    "        params, directory=\"resources/synthetic_val\", files_per_epoch=20\n",
    "    )\n",
    ")\n",
    "\n",
    "# synth_dt.preview(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepatory function defs\n",
    "\n",
    "# customize trainer\n",
    "from lib.train import SeqTrainer\n",
    "from tnibs.train.optim import WarmupCosineLR\n",
    "\n",
    "\n",
    "def eval_legal_movemaking(model, data):\n",
    "    trainer = SeqTrainer(\n",
    "        TrainerConfig.create(\n",
    "            params,\n",
    "        )\n",
    "    )\n",
    "    trainer.init(model, data.loaders())\n",
    "\n",
    "    evaluator = [[], []]\n",
    "\n",
    "    def batch_fun(outputs, batch, batch_num):\n",
    "        for pred_seq, input_seq in zip(map(model.pred, outputs), batch[0]):\n",
    "            try:\n",
    "                original = data.le.inverse_transform(input_seq.flatten().cpu())\n",
    "                evaluator[0].append(original)\n",
    "\n",
    "                decoded = data.le.inverse_transform(pred_seq.flatten().cpu())\n",
    "                evaluator[1].append(decoded)\n",
    "            except:  # noqa: E722\n",
    "                pass\n",
    "\n",
    "    loaders = data.loaders()\n",
    "    loader = loaders[1] if len(loaders) > 1 else loaders[0]\n",
    "\n",
    "    trainer.eval(loader=loader, batch_fun=batch_fun)\n",
    "\n",
    "    total = 0\n",
    "    legal = 0\n",
    "\n",
    "    for game, preds in zip(*evaluator):\n",
    "        board = chess.Board()\n",
    "        for move, pred in zip(game, preds):\n",
    "            if move == \"<PAD>\":\n",
    "                break\n",
    "            else:\n",
    "                board.push_uci(move[1:])\n",
    "                if pred == \"<PAD>\":\n",
    "                    continue\n",
    "                total += 1\n",
    "                if chess.Move.from_uci(pred[1:]) in list(board.legal_moves):\n",
    "                    legal += 1\n",
    "\n",
    "    print(legal, total, legal / total * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184217 272571 67.5849595151355\n",
      "19468 69022 28.205499695749182\n"
     ]
    }
   ],
   "source": [
    "eval_legal_movemaking(rwkv_model, synth_dt)\n",
    "eval_legal_movemaking(gpt_model, synth_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loader 0 (IterableDataset) Preview:\n",
      "--------------------------------------------------\n",
      "Constituent shapes:\n",
      "batch[0]: torch.Size([64, 141]), torch.int64\n",
      "\n",
      "First 1 samples:\n",
      "\n",
      "Sample 0: \n",
      "\n",
      "tensor([1435, 5328, 1440, 6162, 1010, 6078, 1404, 5298, 1256, 5189,  363, 4097,\n",
      "        1527, 4368,  777, 5360, 1497, 5139, 1529, 4436,  158, 4331, 1064, 4156,\n",
      "        1170, 4086, 1076, 5541, 1042, 5949, 2089, 4366, 1373, 5443, 2122, 6106,\n",
      "        1410, 5295, 1380, 5699,  129, 5355, 1214, 4301,  294, 4942, 3567, 4727,\n",
      "         381, 7009,  392, 4786, 3461, 4168, 3013, 4843, 3460,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0])\n",
      "\n",
      "Loader 1 (IterableDataset) Preview:\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/ARCHIVE/Personal/2186474940/.pixi/envs/dev/lib/python3.12/multiprocessing/util.py\", line 303, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/ARCHIVE/Personal/2186474940/.pixi/envs/dev/lib/python3.12/multiprocessing/util.py\", line 227, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/ARCHIVE/Personal/2186474940/.pixi/envs/dev/lib/python3.12/multiprocessing/util.py\", line 136, in _remove_temp_dir\n",
      "    rmtree(tempdir, onerror=onerror)\n",
      "  File \"/ARCHIVE/Personal/2186474940/.pixi/envs/dev/lib/python3.12/shutil.py\", line 759, in rmtree\n",
      "    _rmtree_safe_fd(stack, onexc)\n",
      "  File \"/ARCHIVE/Personal/2186474940/.pixi/envs/dev/lib/python3.12/shutil.py\", line 703, in _rmtree_safe_fd\n",
      "    onexc(func, path, err)\n",
      "  File \"/ARCHIVE/Personal/2186474940/.pixi/envs/dev/lib/python3.12/shutil.py\", line 750, in onexc\n",
      "    return onerror(func, path, exc_info)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/ARCHIVE/Personal/2186474940/.pixi/envs/dev/lib/python3.12/shutil.py\", line 662, in _rmtree_safe_fd\n",
      "    os.rmdir(name, dir_fd=dirfd)\n",
      "OSError: [Errno 39] Directory not empty: '/tmp/pymp-mset5oco'\n",
      "Traceback (most recent call last):\n",
      "  File \"/ARCHIVE/Personal/2186474940/.pixi/envs/dev/lib/python3.12/multiprocessing/util.py\", line 303, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/ARCHIVE/Personal/2186474940/.pixi/envs/dev/lib/python3.12/multiprocessing/util.py\", line 227, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/ARCHIVE/Personal/2186474940/.pixi/envs/dev/lib/python3.12/multiprocessing/util.py\", line 136, in _remove_temp_dir\n",
      "    rmtree(tempdir, onerror=onerror)\n",
      "  File \"/ARCHIVE/Personal/2186474940/.pixi/envs/dev/lib/python3.12/shutil.py\", line 759, in rmtree\n",
      "    _rmtree_safe_fd(stack, onexc)\n",
      "  File \"/ARCHIVE/Personal/2186474940/.pixi/envs/dev/lib/python3.12/shutil.py\", line 703, in _rmtree_safe_fd\n",
      "    onexc(func, path, err)\n",
      "  File \"/ARCHIVE/Personal/2186474940/.pixi/envs/dev/lib/python3.12/shutil.py\", line 750, in onexc\n",
      "    return onerror(func, path, exc_info)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/ARCHIVE/Personal/2186474940/.pixi/envs/dev/lib/python3.12/shutil.py\", line 662, in _rmtree_safe_fd\n",
      "    os.rmdir(name, dir_fd=dirfd)\n",
      "OSError: [Errno 39] Directory not empty: '/tmp/pymp-xbme6uor'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constituent shapes:\n",
      "batch[0]: torch.Size([4, 141]), torch.int64\n",
      "\n",
      "First 1 samples:\n",
      "\n",
      "Sample 0: \n",
      "\n",
      "tensor([1373, 5297, 1010, 4943, 1496, 5422,  366, 4333, 1435, 5360, 1255, 5188,\n",
      "         777, 4728, 1403, 5236,  128, 4983, 2089, 7563,  307, 4395, 1157, 5292,\n",
      "        1063, 7006, 1465, 5266, 1341, 5328, 1440, 5355, 1379, 5094,  545, 5391,\n",
      "         476, 7118, 1382, 7107, 1385, 6164, 3567, 5418,  452, 5414, 1157, 5127,\n",
      "         520, 5021,  890, 5111,  270, 5382, 1526, 7435, 3011, 7211, 3453, 4097,\n",
      "         356, 5387,  178, 4842, 3229, 5001,  249, 4835, 3247, 4827, 3297, 4455,\n",
      "         842, 5260, 3082, 4132, 3416, 4908, 3395, 5443, 1320, 4955,  383, 4884,\n",
      "        3066, 4946, 3175, 4919,  314, 5439, 1501, 4821, 1324, 5384, 1326, 5381,\n",
      "         249, 5021, 1407, 4200, 3166, 5112, 1328, 4365,  895, 4275,  838, 5018,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "elite_dt = PGNData(\n",
    "    PGNDataConfig.create(\n",
    "        params,\n",
    "        directory=\"resources/lichess_elite\",  # irrelevant\n",
    "        val_directory=\"resources/lichess_elite_val\",\n",
    "        files_per_epoch=None,\n",
    "        max_games_per_file=999,\n",
    "    )\n",
    ")\n",
    "\n",
    "elite_dt.preview(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424015 615250 68.91751320601381\n",
      "109593 275547 39.772888109832444\n"
     ]
    }
   ],
   "source": [
    "eval_legal_movemaking(rwkv_model, elite_dt)\n",
    "eval_legal_movemaking(gpt_model, elite_dt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
